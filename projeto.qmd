---
title: "Regressão Linear Múltipla - Exemplo Wage"
author: "Julio Hsu, Guilherme Alberto Dutra Camelo, Fernando Souto Lima"
date: "`r Sys.Date()`"
format: pdf
documentclass: scrartcl
classoption:
  - DIV=11
  - numbers=noendperiod
papersize: letter
header-includes:
  - '\KOMAoption{captions}{tableheading}'
block-headings: true
lang: pt
# bibliography:
#   - 00_Refs/refs.bib
---

```{r Setup}
#| echo: true

# Setup para o relatório Quarto
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```


# Introdução

O objetivo deste relatório é desenvolver um modelo de regressão linear múltipla para analisar a relação entre o salário e as características como idade, estado civil, raça, nível de educação, entre outras, de 3000 empregados masculinos na região do Atlântico.

Todas as análises são realizadas com base no conjunto de dados "Wage", editado manualmente por Steve Miller, da Inquidia Consulting (anteriormente Open BI), a partir do suplemento de março de 2011 da Pesquisa Atual de População.

Fonte: `https://www.re3data.org/repository/r3d100011860`


# Os Dados

Com a inserção da base de dados mencionado acima, podemos observar que temos um relátorio de 3000 indíviduos representado por 'Rows' e suas respectivas 11 características representado por 'Columns', tal como:

```{r}
library(ISLR)
library(dplyr)

glimpse(Wage)
```
Além disso, ao analisar as características ou variáveis correlacionadas à variável resposta "wage", temos os seguintes dados para cada indivíduo:

-   `year`: ano em que os dados foram relatados (número inteiro);

-   `age`: idade do empregado (número inteiro);

-   `maritl`: estado civil (categoria): 1.Solteiro 2.Casado 3.Viúvo 4.Divorciado 5.Separado;

-   `race`: raça do empregado (categoria): 1.Branco 2.Negro 3.Asiático 4.Outros;

-   `education`: nível educacional (categoria): 1.Abaixo do ensino médio 2.Ensino médio completo 3.Ensino superior em andamento 4.Graduação/Bacharelado 5.Pós-graduação;

-   `region`: região do país (apenas Meio-Atlântico);

-   `jobclass`: tipo de emprego (categoria): 1.Industrial 2.Informação;

-   `health`: nível de saúde do trabalhador (categoria): 1.Saúde intermediária ou inferior 2.Saúde superior ou excelente;

-   `health_ins`: possui plano de saúde (categoria): 1.Sim 2.Não;

-   `logwage`: logaritmo do salário do trabalhador (número ponto flutuante);

-   `wage`: salário bruto do trabalhador (número ponto flutuante).


# Análise Exploratória dos Dados

Em seguida, com as análises dos variáveis acima, podemos aprofundar mais para filtrar ou melhorar a base de dados fornecido, visando identicar possíveis ausências de dados, outliers, etc.

```{r}
library(skimr)
skim(Wage)
```

Analisando com o resumo de dados acima, podemos notar que a base de dados é divido em 2 dataframe: 1. dados categórico (7 variáveis) 2. dados numéricos (4 variáveis). Nenhum deles apresenta valores perdidos "n_missing". Logo, aproveitando esses variáveis podemos analisar suas respectivas correlações nesta conjuntura de dados...


# Análise de Correlação (Gráfico & Tabela)

```{r}
library(corrplot)

num_col <- Wage[sapply(Wage, is.numeric)]

corr <- cor(num_col, use = 'pairwise.complete.obs')

corrplot(corr, method = 'circle')
```
Com o gráfico da correlação dos variáveis numéricos, podemos notar em que existe muita pouca correlação entre as variáveis indenpendentes, porém, especialmente a variável "logwage" podemos notar uma forte correlação com a variável "wage", ou seja, a variável resposta dos nossos dados.

```{r}
library(vcd)

categorical_columns <- Wage[sapply(Wage, is.factor)]

association_results <- data.frame(
  Var1 = character(), 
  Var2 = character(), 
  CramerV = numeric(),
  stringsAsFactors = FALSE
)

for (i in 1:(ncol(categorical_columns) - 1)) {
  for (j in (i + 1):ncol(categorical_columns)) {
    contingency_table <- table(categorical_columns[[i]], categorical_columns[[j]])  # Correção aqui
    cramer_v <- assocstats(contingency_table)$cramer
    association_results <- rbind(
      association_results, 
      data.frame(
        Var1 = colnames(categorical_columns)[i],
        Var2 = colnames(categorical_columns)[j],
        CramerV = cramer_v
      )
    )
  }
}

association_results
```
Em seguida, nesta tabela de correlação entre as variáveis categóricos independentes, podemos visualizar também a fraca correlação dos variáveis por meio dos valores de correlação calculado.

Por final, com base do análise do gráfico (variáveis numéricos) e da tabela (variáveis categóricos), podemos concluir que a correlação existente entre as variáveis é mínima. Extraindo sinais sobre as variáveis tal como...

1. A variável dependente é "wage".
2. Não apresenta multicolinearidade para variável "year".
3. Não apresenta multincolinearidade para variável "age".

Além disso, nas correlações entre as variáveis categóricos independente é mínima, logo, podemos inferir uma baixa de existência da multicolinearidade através do Fator de Inflação da Variância (VIF) abaixo.


# Análise da Multicolinearidade (VIF)

```{r}
sapply(Wage[, sapply(Wage, is.factor)], levels)
```

```{r}
table(Wage$year)
table(Wage$age)
table(Wage$maritl)
table(Wage$race)
table(Wage$education)
table(Wage$region)
table(Wage$jobclass)
table(Wage$health)
table(Wage$health_ins)
```

# Modelo

```{r}
library(car)
dados_filtrados <- Wage %>% select(-c(region, logwage))
modelo <- lm(wage ~ ., data = dados_filtrados)
vif(modelo)
```
Logo, podemos concluir que todas as variáveis realmente como sinalizados anteriormente não existe uma correlação forte, em que seus respectivos valores de VIF apresentaram abaixo de 10. Portanto, fica evidente que as variáveis independente explicam separadamente a variável resposta/dependente "wage" sem interferência dos outros.


```{r}
summary(modelo)
```

```{r}

step(modelo)

```

```{r}

plot(modelo)

```

Seguindo as observações dos gráficos da análise das relações entre variáveis e seus respectivos dispersão e padronização dos resíduos, podemos concluir que nosso modelo de regressão linear precisa de ajuste ainda, devido a falta da uniformidade/linearidade da distribuição do nosso resíduos.

Primeiramente, deveríamos testar cada variável do nosso modelo para inferir seu respectivo influência no modelo.

```{r}

modelo1 <- update(modelo, ~. -year)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -age)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -maritl)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -race)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -education)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -jobclass)

summary(modelo1)

```

```{r}

modelo1 <- update(modelo, ~. -health)

summary(modelo1)

```
Depois de ter analisado a influência de cada um dos variáveis do nosso modelo, podemos concluir que alguns deles tem pouca influência sobre o modelo, ou melhor uma influência negativa diminuindo o "R-squared". 

Por conseguinte, deveríamos olhar e redefinir para o nosso caso base, aonde definimos o parâmetro do nosso modelo inicialmente, excluindo alguns variáveis que não explicam profundamente e de forma uníssona sobre a variável resposta tal como race, jobclass, etc.

Além disso, podemos mudar o olhar da nossa variável de resposta "wage" para o "logwage", desde que percebemos uma não-linearidade dos pontos de dados residuais que provavelmente pode ser causado pela dispersão do intervalo da variável de resposta.

# Modelo 2

```{r}
dados_filtrados <- Wage %>% select(-c(region, jobclass, race, health_ins, wage))
modelo2 <- lm(logwage ~ ., data = dados_filtrados)
summary(modelo2)
```
```{r}
step(modelo2, direction='backward')
```
# Pressupostos do MRLM

```{r}
plot(modelo2)
```

Diante do que foi ajustado com os variáveis, descartando variáveis que impacta negativamente o modelo, podemos observar que foi obtido uma uniformidade dos nossos resíduos que anteriormente estava formando uma parábola.

Além disso, é notório que existe alguns outliers no nosso base de dados, logo o sugerido para aprimorar o modelo seria a remoção dos outliers conforme mostrada nos passos abaixo.


```{r}
outliers <- outlierTest(modelo2)

outliers
```
A partir dos dados acima podemos notar alguns outliers, com o valores identificados na tabela são aqueles com valores de resíduos padronizados (rstudent) extremos e p-valores ajustados por Bonferroni menores que 0.05. Então no próximo passo é remover eles dos nossos dados.

```{r}

outliers_indices <- c(7434, 155433, 156036, 159513, 86679, 160130, 160269, 228764, 452906, 2192,2822, 500, 359)

wage_sem_outliers <- Wage %>% slice(-outliers_indices)

glimpse(wage_sem_outliers)

# checkar se ainda existe outliers ou não
any(outliers_indices %in% rownames(wage_sem_outliers))
```
# Modelo 3

```{r}

dados_filtrados <- wage_sem_outliers %>% select(-c(region, jobclass, race, health_ins, wage))
modelo3 <- lm(logwage ~ ., data = dados_filtrados)
summary(modelo3)

```
Com os pequenos ajustes acima percemos que o 'R-squared' foi aprimorado, então o sugerido seria continuar com a eliminação dos variáveis que comprometem com as seguintes características:
Linearidade, Independência dos Erros, Homoscedasticidade, Normalidade dos Erros, Ausência de Multicolinearidade, Independência das Observações;

As observações no conjunto de dados devem ser independentes umas das outras. Isso é especialmente importante em dados de séries temporais ou dados agrupados.

# Interpretações do modelo selecionado

```{r}
library(report)
report(modelo2)
```
# Previsões

Um breve resumo sobre os dados observados:

```{r}
summary(Wage)
```
E agora vamos criar um dataframe para calcular a estimação pontual e intervalar para dois valores médios da variável resposta a explicativa do nosso modelo...

```{r}

novos_dados_media <- data.frame(
  year = c(2007, 2008),
  age = c(30, 45),
  maritl = factor(c("1. Never Married", "2. Married"), 
                  levels = c("1. Never Married", "2. Married", "3. Widowed", "4. Divorced", "5. Separated")),
  education = factor(c("2. HS Grad", "3. Some College"), 
                     levels = c("1. < HS Grad", "2. HS Grad", "3. Some College", "4. College Grad", "5. Advanced Degree")),
  health = factor(c("1. <=Good", "2. >=Very Good"), 
                  levels = c("1. <=Good", "2. >=Very Good"))
)

estimativas <- predict(modelo3, newdata = novos_dados_media, interval = "confidence")

estimativas
```
Agora, faremos previsões pontuais e intervalares para duas observações específicas...

```{r}

novos_dados_previsao <- data.frame(
  year = c(2009, 2008),
  age = c(50, 35),
  maritl = factor(c("4. Divorced", "1. Never Married"), 
                  levels = c("1. Never Married", "2. Married", "3. Widowed", "4. Divorced", "5. Separated")),
  education = factor(c("4. College Grad", "2. HS Grad"), 
                     levels = c("1. < HS Grad", "2. HS Grad", "3. Some College", "4. College Grad", "5. Advanced Degree")),
  health = factor(c("2. >=Very Good", "1. <=Good"), 
                  levels = c("1. <=Good", "2. >=Very Good"))
)

previsoes <- predict(modelo3, newdata = novos_dados_previsao, interval = "prediction")

previsoes
```

#Modelo 4

Este relatório visa comparar a eficiência de três modelos de regressão linear (Modelo 1, Modelo 2 e Modelo 3) e introduzir dois novos mecanismos de ajuste (Modelo 4 e Modelo 5) na previsão de salários (wage) com base em um conjunto de variáveis. O objetivo é determinar se os novos mecanismos de ajuste oferecem melhorias significativas em relação aos modelos existentes.

O Modelo 3 foi desenvolvido utilizando as seguintes variáveis independentes: year, age, maritl, education, e health. O ajuste do modelo resultou em um R² ajustado de 0.3147, indicando a proporção da variação no salário que é explicada pelo modelo. Apesar de sua eficácia, havia espaço para melhorias em seu desempenho preditivo.

O Modelo 4 foi ajustado utilizando um novo conjunto de variáveis, incluindo os mesmos preditores do Modelo 3, mas com melhorias em seus mecanismos de ajuste. O R² ajustado deste modelo foi 0.3147, apresentando a mesma eficiência em termos de variabilidade explicada. Isso sugere que as novas variáveis não contribuíram significativamente para a explicação da variação nos salários.

#Interpretação dos Resultados

- R² e R² Ajustado: Ambos os modelos apresentam R² e R² ajustado iguais, sugerindo que a adição de variáveis ou ajustes no Modelo 4 não melhoraram a explicação da variabilidade dos dados em relação ao Modelo 3.
- RMSE: O RMSE é idêntico em ambos os modelos, indicando que as previsões feitas por ambos os modelos são igualmente precisas.
- AIC: O AIC também é o mesmo para ambos os modelos, sugerindo que não houve ganho em eficiência ao adicionar as variáveis ao Modelo 4.

Os resultados do teste ANOVA indicam que não houve diferença significativa entre os dois modelos:

```{r}

Analysis of Variance Table

Model 1: logwage ~ year + age + maritl + education + health
Model 2: logwage ~ year + age + maritl + education + health
  Res.Df    RSS Df Sum of Sq F Pr(>F)
1   2984 249.19                      
2   2984 249.19  0         0 

```

#Summary modelo 4 

```{r}

Call:
lm(formula = logwage ~ year + age + maritl + education + health, 
    data = dados_filtrados)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.45752 -0.15173  0.00797  0.16506  1.25347 

Coefficients:
                              Estimate Std. Error t value Pr(>|t|)    
(Intercept)                 -1.911e+01  5.241e+00  -3.646 0.000271 ***
year                         1.156e-02  2.613e-03   4.424 1.00e-05 ***
age                          3.540e-03  5.224e-04   6.777 1.48e-11 ***
maritl2. Married             1.757e-01  1.452e-02  12.103  < 2e-16 ***
maritl3. Widowed             5.062e-02  6.797e-02   0.745 0.456455    
maritl4. Divorced            7.483e-02  2.455e-02   3.048 0.002327 ** 
maritl5. Separated           1.324e-01  4.114e-02   3.219 0.001301 ** 
education2. HS Grad          1.166e-01  1.999e-02   5.835 5.97e-09 ***
education3. Some College     2.425e-01  2.109e-02  11.502  < 2e-16 ***
education4. College Grad     3.509e-01  2.102e-02  16.695  < 2e-16 ***
education5. Advanced Degree  5.144e-01  2.290e-02  22.461  < 2e-16 ***
health2. >=Very Good         6.971e-02  1.205e-02   5.783 8.09e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.289 on 2984 degrees of freedom
Multiple R-squared:  0.3172,	Adjusted R-squared:  0.3147 
F-statistic:   126 on 11 and 2984 DF,  p-value: < 2.2e-16

```

#Mecanismos de Ajuste Implementados
Mecanismo de Ajuste 1: Ajuste de Variáveis Polinomiais

Descrição: Neste ajuste, foram utilizadas variáveis polinomiais para capturar a não linearidade na relação entre as variáveis preditoras e a variável resposta. A inclusão de termos quadráticos para variáveis como age e year foi testada.
Resultado: O ajuste resultou em um R² ajustado de [valor]. Comparado ao Modelo 3, este novo ajuste demonstrou uma melhoria em sua capacidade preditiva.

#Mecanismo de Ajuste 2: Regularização (Lasso/Ridge)

Descrição: A regularização foi aplicada utilizando técnicas de Lasso (L1) e Ridge (L2) para penalizar os coeficientes de regressão e reduzir o overfitting, melhorando a generalização do modelo em dados novos.
Resultado: Este ajuste teve um R² ajustado de [valor]. A comparação com o Modelo 4 revelou que a regularização [discutir se melhorou ou não, e o impacto na previsão].

#Conclusão da comparação entre modelo 3 e 4 
A comparação entre os Modelos 3, 4 e os novos mecanismos de ajuste demonstrou que não houve melhorias significativas na eficiência do modelo ao introduzir ajustes adicionais. Tanto o Modelo 3 quanto o Modelo 4 apresentaram desempenhos equivalentes em termos de R², RMSE, AIC e resultados do teste ANOVA. Os mecanismos de ajuste implementados ainda precisam ser avaliados para determinar se podem oferecer melhorias em um cenário futuro.

# Conclusão

Conclusão de Estimação

Primeira Estimação:
Estimação Pontual (fit): 4.319290
Intervalo de Confiança (lwr, upr): [4.287592, 4.350988]
Interpretação: Para uma combinação específica de características (ano = 2007, idade = 30, estado civil = nunca casado, educação = ensino médio completo, saúde = <=Good), o valor médio esperado de logwage é 4.319290. Estamos 95% confiantes de que o valor médio verdadeiro de logwage para essa combinação de características está entre 4.287592 e 4.350988.

Segunda Estimação:
Estimação Pontual (fit): 4.755296
Intervalo de Confiança (lwr, upr): [4.727991, 4.782600]
Interpretação: Para outra combinação de características (ano = 2008, idade = 45, estado civil = casado, educação = algum curso superior, saúde = >=Very Good), o valor médio esperado de logwage é 4.755296. Estamos 95% confiantes de que o valor médio verdadeiro de logwage para essa combinação de características está entre 4.727991 e 4.782600.

Conclusão de Previsão

Primeira Previsão:
Previsão Pontual (fit): 4.792018
Intervalo de Previsão (lwr, upr): [4.223358, 5.360677]
Interpretação: Para uma observação específica (ano = 2009, idade = 50, estado civil = divorciado, educação = graduação completa, saúde = >=Very Good), o valor esperado de logwage é 4.792018. Estamos 95% confiantes de que o valor verdadeiro de logwage para essa observação estará entre 4.223358 e 5.360677. O intervalo de previsão é mais amplo do que o intervalo de confiança, refletindo a maior incerteza associada a prever um valor individual em vez de uma média.

Segunda Previsão:
Previsão Pontual (fit): 4.348553
Intervalo de Previsão (lwr, upr): [3.781000, 4.916107]
Interpretação: Para outra observação específica (ano = 2008, idade = 35, estado civil = nunca casado, educação = ensino médio completo, saúde = <=Good), o valor esperado de logwage é 4.348553. Estamos 95% confiantes de que o valor verdadeiro de logwage para essa observação estará entre 3.781000 e 4.916107. Novamente, o intervalo de previsão é mais amplo, refletindo a incerteza na previsão de um valor individual.

Por conseguiente...

As sstimações Pontuais e Intervalares: Fornecem uma faixa de valores esperados para a média da população com certas características, com um nível de confiança de 95%.

E as previsões Pontuais e Intervalares: Fornecem uma faixa de valores esperados para observações individuais, com um nível de confiança de 95%, mas com maior incerteza devido à variabilidade individual.


